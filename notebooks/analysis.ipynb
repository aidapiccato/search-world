{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pickle as pkl\n",
    "import os\n",
    "from pathlib import Path\n",
    "import fnmatch\n",
    "\n",
    "from glob import glob\n",
    "import search_world\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in scalar and vector data filenames for a specific path\n",
    "job_id = ''\n",
    "data_dir = os.path.join('../logs/', job_id)\n",
    "config_fns = [fname for root, _, _ in os.walk(data_dir) for fname in glob(os.path.join(root, 'config.log'))]\n",
    "scalar_fns = [fname for root, _, _ in os.walk(data_dir) for fname in glob(os.path.join(root, 'scalar'))]\n",
    "vector_fns = [fname for root, _, _ in os.walk(data_dir) for fname in glob(os.path.join(root, 'vector'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all together now\n",
    "scalar_arrs = []\n",
    "vector_dfs = []\n",
    "scalar_dicts = []\n",
    "for idx, (vector_fn, scalar_fn) in enumerate(zip(vector_fns, scalar_fns)):\n",
    "    with open(scalar_fn, 'rb') as f:\n",
    "        a = pkl.load(f)       \n",
    "    scalar_dict = a['env'].info()    \n",
    "    scalar_dict.update({'dataset_index': idx})\n",
    "#     scalar_dict.update(a['model'].info())\n",
    "    scalar_dicts.append(scalar_dict)\n",
    "\n",
    "    with open(vector_fn, 'rb') as f:\n",
    "        vector_dicts = pkl.load(f)\n",
    "        flattened_vector_dicts = []        \n",
    "        for d in vector_dicts:\n",
    "            t = {}\n",
    "            for k, v in d.items():\n",
    "                if isinstance(v, dict):\n",
    "                    for nested_k, nested_v in v.items():        \n",
    "                        t.update({nested_k: nested_v})\n",
    "                else:\n",
    "                    t.update({k: v})      \n",
    "            flattened_vector_dicts.append(t)\n",
    "        df = pd.DataFrame(flattened_vector_dicts) \n",
    "        df['dataset_index'] = idx\n",
    "        df['trial_index'] = df.done.cumsum().shift(fill_value=0)\n",
    "        changes = df.columns.difference(['trial_index', 'dataset_index', 'job_id']).tolist()        \n",
    "\n",
    "        f = lambda x: x.tolist() if len(x) > 1 else x\n",
    "\n",
    "        df = df.groupby(['job_id', 'dataset_index', 'trial_index'])[changes].agg(f).reset_index()\n",
    "        df['done'] = df.done.apply(lambda x: [x] if isinstance(x, bool) else x)\n",
    "        df = df[df.apply(lambda x: True in x.done, axis=1)].reset_index()\n",
    "        df.trial_index += idx\n",
    "        vector_dfs.append(df)\n",
    "scalar_df = pd.DataFrame(scalar_dicts)\n",
    "df = pd.concat(vector_dfs).reset_index()\n",
    "df = df.merge(scalar_df, on='dataset_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: new column for initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "condition = ['length', 'n_corridors', 'agent_initial_position', 'target_position']\n",
    "df = df.set_index(condition) # grouping by initial condition and maze configuratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9088121286254445"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Find number of trials per condition\n",
    "# TODO: Find agent score on each trial \n",
    "df['agent_dist'] = df.apply(lambda x: len(x.action), axis=1)\n",
    "df['agent_score'] = 1 - (df.agent_dist - df.min_dist)/(df.max_dist - df.min_dist)\n",
    "# TODO: Splitting dataframe into two datasets per condition\n",
    "grouped_df = df.groupby(condition)\n",
    "def mask(n, p=0.5):\n",
    "    a = np.zeros(n, dtype=int)\n",
    "    a[:int(p * n)] = 1\n",
    "    np.random.shuffle(a)\n",
    "    a = a.astype(bool)\n",
    "    return a\n",
    "masks = grouped_df.index.agg('count').agg(lambda x: mask(x)).to_frame()\n",
    "df1 = grouped_df.apply(lambda x: x[masks.loc[x.index[0]][0]])\n",
    "df2 = grouped_df.apply(lambda x: x[~masks.loc[x.index[0]][0]])\n",
    "# TODO: Average scores across trials with the same condition\n",
    "condition_scores_df1 = df1.groupby(['length', 'n_corridors', 'agent_initial_position', 'target_position']).agent_score.mean().to_frame()\n",
    "condition_scores_df2 = df2.groupby(['length', 'n_corridors', 'agent_initial_position', 'target_position']).agent_score.mean().to_frame()\n",
    "# TODO: Repeat this to do multi-step cross validation\n",
    "# TODO: Compare average scores across trials of different agents\n",
    "merged = condition_scores_df1.merge(condition_scores_df2, on=['length', 'n_corridors', 'agent_initial_position', 'target_position'])\n",
    "print('MLS correlation': merged.agent_score_x.corr(merged.agent_score_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of unique conditions: 261\n",
      "avg. no. of trials per condition: 51.71 ± 40.88\n"
     ]
    }
   ],
   "source": [
    "print('no. of unique conditions: %d' % len(df.index.unique()))\n",
    "print('avg. no. of trials per condition: %.2f ± %.2f' % (df.groupby(condition).index.count().mean(), df.groupby(condition).index.count().std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6e3ca02e21df2c11be293665b3921e482d7134cf4196f0ee5b53074ad14687e"
  },
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
